{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from scipy.io import loadmat\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data types\n",
    "@dataclass\n",
    "class Dataset_SVHN:\n",
    "    \"\"\"\n",
    "    X: np.ndarray of shape (26032, 32, 32, 3) => (image_number, Y=row, X=column, RGB)\n",
    "        containing the 32x32 pixel3 color number images\n",
    "        \n",
    "    y: np.array of shape (26032, 1) => (image_number, int_label==>[0..9])\n",
    "        containing the labels (actual numbers) of the images\n",
    "    \n",
    "    \n",
    "    # The Street View House Numbers (SVHN) Dataset\n",
    "    \n",
    "    SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal\n",
    "    requirement on data preprocessing and formatting.\n",
    "    It can be seen as similar in flavor to MNIST (e.g., the images are of small cropped digits), but incorporates an\n",
    "    order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved,\n",
    "    real world problem (recognizing digits and numbers in natural scene images).\n",
    "    SVHN is obtained from house numbers in Google Street View images.\n",
    "    \"\"\"\n",
    "\n",
    "    # def __init__(self, X: np.ndarray, y: np.array):\n",
    "    #     self.X = X\n",
    "    #     self.y = y\n",
    "    \n",
    "    def __init__(self, X: np.ndarray, y: np.array):\n",
    "        self.X = X\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data():\n",
    "    data_train = loadmat('train_32x32.mat')\n",
    "    data_test = loadmat('test_32x32.mat')\n",
    "\n",
    "    return (data_train, data_test)\n",
    "\n",
    "\n",
    "def shapeshift_input_data(X: np.ndarray):\n",
    "    # convert shape: (32, 32, 3, 26032) to: (26032, 32, 32, 3) => (image_number, Y=row, X=column, RGB)\n",
    "    return np.moveaxis(X, -1, 0)\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "    (train, test) = load_data()\n",
    "\n",
    "    shifted_train_X = shapeshift_input_data(train['X'])\n",
    "    shifted_test_X = shapeshift_input_data(test['X'])\n",
    "\n",
    "    train = Dataset_SVHN(shifted_train_X, train['y'])\n",
    "    test = Dataset_SVHN(shifted_test_X, test['y'])\n",
    "\n",
    "    return (train, test)\n",
    "\n",
    "\n",
    "(train, test) = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_example_number():\n",
    "    plt.axis('off')\n",
    "    plt.imshow(train.X[0])\n",
    "    \n",
    "\n",
    "plot_example_number()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def set_compute_device():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "set_compute_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def configure_run():\n",
    "    return {\n",
    "        \"epoch_count\": 10,\n",
    "        # since there are classifications of 10 a multiple of that should hopefully always have roughly equal amounts of\n",
    "        # each classification in a batch size\n",
    "        \"batch_size\": 100\n",
    "    }\n",
    "\n",
    "config = configure_run()\n",
    "#config[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.X[0])\n",
    "\n",
    "def transformer():\n",
    "    # alias for readability\n",
    "    tf = torchvision.transforms\n",
    "    \n",
    "    transform = tf.Compose([\n",
    "        tf.ToTensor()\n",
    "    ])    \n",
    "    return transform\n",
    "\n",
    "transform = transformer()\n",
    "\n",
    "transformed_train_X = [transform(sample) for sample in train.X]\n",
    "transformed_test_X = [transform(sample) for sample in test.X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `pin_memory` argument for better GPU performance\n",
    "loader_train = torch.utils.data.DataLoader(\n",
    "    transformed_train_X,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True)\n",
    "\n",
    "loader_test = torch.utils.data.DataLoader(\n",
    "    transformed_test_X,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch():\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n",
    "        break\n",
    "\n",
    "\n",
    "show_batch(trainloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorflow-24-02-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
